{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, add\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def extract_features(img_path, model):\n",
    "    img = preprocess_image(img_path)\n",
    "    features = model.predict(img, verbose=0)\n",
    "    return features\n",
    "\n",
    "def load_dataset(df):\n",
    "    images = df['image'].values\n",
    "    captions = df['caption'].values\n",
    "    return images, captions\n",
    "\n",
    "def create_tokenizer(captions):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(captions)\n",
    "    return tokenizer\n",
    "\n",
    "def max_length(captions):\n",
    "    return max(len(caption.split()) for caption in captions)\n",
    "\n",
    "def define_model(vocab_size, max_length):\n",
    "    inputs1 = tf.keras.layers.Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "    \n",
    "    inputs2 = tf.keras.layers.Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "    \n",
    "    decoder1 = add([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "    \n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def train_model(model, tokenizer, max_length, df, photos, epochs=20):\n",
    "    for i in range(epochs):\n",
    "        for idx, row in df.iterrows():\n",
    "            photo = photos[row['image']]\n",
    "            caption = row['caption']\n",
    "            seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "            for j in range(1, len(seq)):\n",
    "                in_seq, out_seq = seq[:j], seq[j]\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                out_seq = tf.keras.utils.to_categorical([out_seq], num_classes=len(tokenizer.word_index) + 1)[0]\n",
    "                model.fit([photo, in_seq], out_seq, epochs=1, verbose=0)\n",
    "\n",
    "def generate_caption(model, tokenizer, photo, max_length):\n",
    "    in_text = 'startseq'\n",
    "    for _ in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([photo, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = tokenizer.index_word[yhat]\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text\n",
    "\n",
    "# Example Usage\n",
    "def main():\n",
    "    # Load the dataset into a DataFrame\n",
    "    data = {\n",
    "        'image': ['dif.png', 'Designer (4).jpeg', 'Designer (5).jpeg','Designer (6).jpeg' ],\n",
    "        'caption': ['a dog is running in a field', 'a dog is playing outside', 'a cat is sitting on a sofa', 'a cat is relaxing indoors']\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Load InceptionV3 model\n",
    "    base_model = InceptionV3(weights='imagenet')\n",
    "    model = Model(base_model.input, base_model.layers[-2].output)\n",
    "    \n",
    "    # Load dataset\n",
    "    images, all_captions = load_dataset(df)\n",
    "    \n",
    "    # Create tokenizer\n",
    "    tokenizer = create_tokenizer(all_captions)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    max_length_ = max_length(all_captions)\n",
    "    \n",
    "    # Define the captioning model\n",
    "    caption_model = define_model(vocab_size, max_length_)\n",
    "    \n",
    "    # Extract features for all images\n",
    "    photos = {img: extract_features(img, model) for img in images}\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(caption_model, tokenizer, max_length_, df, photos, epochs=20)\n",
    "    \n",
    "    # Generate caption for a test image\n",
    "    test_image ='image1.jpg'\n",
    "    features = extract_features(test_image, model)\n",
    "    caption = generate_caption(caption_model, tokenizer, features, max_length_)\n",
    "    print(caption)\n",
    "\n",
    "if __name__ == \"_main_\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
